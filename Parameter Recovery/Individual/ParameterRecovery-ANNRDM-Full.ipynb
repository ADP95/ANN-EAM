{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c082ae-54dc-4a69-99f3-5a6f0155c1ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cmdstanpy \n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "import os\n",
    "import json\n",
    "from utils.random import simulate_ANNRDM_individual\n",
    "from utils.utils import get_parameters_range, hdi\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24adb6c4-ed00-40b3-a188-67df8a0c4614",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.serif\"] = [\"Times New Roman\"] + plt.rcParams[\"font.serif\"]\n",
    "plt.rcParams[\"pdf.fonttype\"] = 42\n",
    "plt.rcParams[\"pdf.use14corefonts\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec84a9b1-6d9c-4896-a2ec-71c2ada7c986",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = \"../../\"\n",
    "plots_root = \"Results/individual/Plots/\"\n",
    "datasets_root = root + \"Datasets/\"\n",
    "behavioural_data_root = datasets_root +  \"behavioral_data/selected_data/\" \n",
    "\n",
    "dataset_path = datasets_root + \"AI Models Results/FastText_FC.csv\"\n",
    "stan_file_path = root +  \"models/stan/ANN-RDM/individual/sigmoid_am_ndm.stan\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d434dd8-9732-4cf0-a688-d8e2f774fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_participants = 2\n",
    "n_trials = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a7128a-7789-4eff-b14d-e9d6ee8eddd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set sampling parameters\n",
    "n_iter = 4000\n",
    "n_warmup = int(n_iter/2)\n",
    "n_sample = int(n_iter/2)\n",
    "n_chains = 2\n",
    "\n",
    "threshold_priors = [2, 1]          # For all models with RDM\n",
    "ndt_priors = [0, 1];               # For models wtihout non-decision time modulation\n",
    "g_priors = [-2, 1]                 # For models wtih non-decision time modulation\n",
    "m_priors = [0, 0.5]                # For models wtih non-decision time modulation\n",
    "drift_priors = [1, 2]              # For models without drift mapping functions (non ANN-EAM models)\n",
    "alpha_priors = [0, 1]              # For models with drift mapping functions\n",
    "b_priors = [0, 1]                  # For models with drift mapping functions with asymptote modulation and linear models\n",
    "k_priors = [2, 1]                  # For models with sigmoid drift mapping functions (ANN-EAM models)\n",
    "\n",
    "def get_stan_parameters(generated_df):\n",
    "    N = len(generated_df)                                                    # For all models\n",
    "    p = generated_df.loc[:, [\"word_prob\", \"non_word_prob\"]].to_numpy()       # predicted probabilites of words and non-words, for ANN-EAM models\n",
    "    frequency = generated_df[\"zipf\"].to_numpy().astype(int)                  # zipf values, for models with non-decision time or drift modulation\n",
    "    frequencyCondition = generated_df[\"category\"].replace([\"HF\", \"LF\", \"NW\"], [1, 2, 3]).to_numpy() # For models with conditional drift\n",
    "    response = generated_df[\"response\"].to_numpy().astype(int)               # for all models\n",
    "    rt = generated_df[\"rt\"].to_numpy()                                       # for all models\n",
    "    minRT = generated_df[\"minRT\"].to_numpy()                                 # for all models\n",
    "    RTbound = 0.1                                                             # for all models\n",
    "\n",
    "    # define input for the model\n",
    "    data_dict = {\"N\": N,\n",
    "                 \"response\": response,\n",
    "                 \"rt\": rt,\n",
    "                 \"minRT\": minRT,\n",
    "                 \"RTbound\": RTbound,\n",
    "                 \"frequency\": frequency,\n",
    "                 \"frequencyCondition\": frequencyCondition,\n",
    "                 \"threshold_priors\": threshold_priors,\n",
    "                 \"ndt_priors\": ndt_priors,\n",
    "                 \"g_priors\": g_priors,\n",
    "                 \"m_priors\": m_priors,\n",
    "                 \"drift_priors\": drift_priors,\n",
    "                 \"p\": p,\n",
    "                 \"alpha_priors\": alpha_priors,\n",
    "                 \"b_priors\": b_priors,\n",
    "                 \"k_priors\": k_priors,\n",
    "                 }\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b839e-3dcd-4343-97fa-3ca0288235be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_to_csv(fit, parameters_set):\n",
    "    columns = {\"mean_alpha\":-1, \"mean_b\":-1, \"mean_k_1\":-1, \n",
    "               \"mean_k_2\":-1,\"mean_g\":-1, \"mean_m\":-1,\n",
    "               \"mean_threshold_word\":-1, \"mean_threshold_nonword\":-1,\n",
    "               \"median_alpha\":-1, \"median_b\":-1, \"median_k_1\":-1, \n",
    "               \"median_k_2\":-1, \"median_g\":-1, \"median_m\":-1,\n",
    "               \"median_threshold_word\":-1, \"median_threshold_nonword\":-1}\n",
    "    \n",
    "    recoverd_df = pd.DataFrame([], columns=columns.keys())\n",
    "    stan_variables = fit.stan_variables()\n",
    "\n",
    "    columns[\"mean_k_1\"] = stan_variables[\"transf_k_1\"].mean()\n",
    "    columns[\"median_k_1\"] = np.median(stan_variables[\"transf_k_1\"])\n",
    "    columns[\"real_k_1\"] = parameters_set.loc[\"k_1\", \"generated\"]\n",
    "    columns[\"HDI_k_1_bottom\"], columns[\"HDI_k_1_top\"] = hdi(stan_variables[\"transf_k_1\"])\n",
    "\n",
    "    columns[\"mean_k_2\"] = stan_variables[\"transf_k_2\"].mean()\n",
    "    columns[\"median_k_2\"] = np.median(stan_variables[\"transf_k_2\"])\n",
    "    columns[\"real_k_2\"] = parameters_set.loc[\"k_2\", \"generated\"]\n",
    "    columns[\"HDI_k_2_bottom\"], columns[\"HDI_k_2_top\"] = hdi(stan_variables[\"transf_k_2\"])\n",
    "    \n",
    "    columns[\"mean_alpha\"] = stan_variables[\"transf_alpha\"].mean()\n",
    "    columns[\"median_alpha\"] = np.median(stan_variables[\"transf_alpha\"])\n",
    "    columns[\"real_alpha\"] = parameters_set.loc[\"alpha\", \"generated\"]\n",
    "    columns[\"HDI_alpha_bottom\"], columns[\"HDI_alpha_top\"] = hdi(stan_variables[\"transf_alpha\"])\n",
    "\n",
    "    columns[\"mean_b\"] = stan_variables[\"transf_b\"].mean()\n",
    "    columns[\"median_b\"] = np.median(stan_variables[\"transf_b\"])\n",
    "    columns[\"real_b\"] = parameters_set.loc[\"b\", \"generated\"]\n",
    "    columns[\"HDI_b_bottom\"], columns[\"HDI_b_top\"] = hdi(stan_variables[\"transf_b\"])\n",
    "    \n",
    "    columns[\"mean_g\"] = stan_variables[\"transf_g\"].mean()\n",
    "    columns[\"median_g\"] = np.median(stan_variables[\"transf_g\"])\n",
    "    columns[\"real_g\"] = parameters_set.loc[\"g\", \"generated\"]\n",
    "    columns[\"HDI_g_bottom\"], columns[\"HDI_g_top\"] = hdi(stan_variables[\"transf_g\"])\n",
    "    \n",
    "    columns[\"mean_m\"] = stan_variables[\"transf_m\"].mean()\n",
    "    columns[\"median_m\"] = np.median(stan_variables[\"transf_m\"])\n",
    "    columns[\"real_m\"] = parameters_set.loc[\"m\", \"generated\"]\n",
    "    columns[\"HDI_m_bottom\"], columns[\"HDI_m_top\"] = hdi(stan_variables[\"transf_m\"])\n",
    "\n",
    "    columns[\"mean_threshold_word\"] = stan_variables[\"transf_threshold_word\"].mean()\n",
    "    columns[\"median_threshold_word\"] = np.median(stan_variables[\"transf_threshold_word\"])\n",
    "    columns[\"real_threshold_word\"] = parameters_set.loc[\"threshold_word\", \"generated\"]\n",
    "    columns[\"HDI_threshold_word_bottom\"], columns[\"HDI_threshold_word_top\"] = hdi(stan_variables[\"transf_threshold_word\"])\n",
    "    \n",
    "    columns[\"mean_threshold_nonword\"] = stan_variables[\"transf_threshold_nonword\"].mean()\n",
    "    columns[\"median_threshold_nonword\"] = np.median(stan_variables[\"transf_threshold_nonword\"])\n",
    "    columns[\"real_threshold_nonword\"] = parameters_set.loc[\"threshold_nonword\", \"generated\"]\n",
    "    columns[\"HDI_threshold_nonword_bottom\"], columns[\"HDI_threshold_nonword_top\"] = hdi(stan_variables[\"transf_threshold_nonword\"])\n",
    "    \n",
    "    recoverd_df = pd.concat([recoverd_df, pd.DataFrame(columns, index=[0])])\n",
    "\n",
    "    output_path=\"ANNRDM_FULL_recovery_results.csv\"\n",
    "    recoverd_df.to_csv(output_path,\n",
    "                       mode=\"a\",\n",
    "                       header=not os.path.exists(output_path),\n",
    "                       index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c650ddcb-6e9b-428a-8079-31f094d02306",
   "metadata": {
    "id": "123c4809-7b46-4f8d-b578-0d5e9fb5fbe7"
   },
   "source": [
    "## Simulation and Estimation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5984d029-7aee-467e-b4f7-5a4024728e8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_nword_df = pd.read_csv(dataset_path, header=None,\n",
    "                            names =[\"string\", \"freq\",  \"label\", \"zipf\",\n",
    "                                    \"category\", \"word_prob\", \"non_word_prob\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6abe12-2840-4fee-a05d-5cb76d8d597f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 93380,
     "status": "ok",
     "timestamp": 1651313346844,
     "user": {
      "displayName": "Arash Dadras",
      "userId": "05722346836148265544"
     },
     "user_tz": -270
    },
    "id": "c1b3627d-0ea2-49b6-86f0-7b098a5a16d6",
    "outputId": "4bc8643c-82c0-4fc9-99a0-7f232fa1eea4",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "rdm_model = cmdstanpy.CmdStanModel(model_name=\"ANN-RDM_full_FC\",\n",
    "                                   stan_file=stan_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6150e810-7b86-4834-ba91-d78ea4343730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iteration_count = 0\n",
    "params_range = pd.read_csv(\"../Data/params_range.csv\", index_col=0)\n",
    "while iteration_count < number_of_participants:\n",
    "    print(f\"Iteration for participant {iteration_count+1} Started\")\n",
    "    parameters_set = params_range.copy()\n",
    "    parameters_set[\"generated\"] = np.random.normal(loc=parameters_set.iloc[:, 0],\n",
    "                                                   scale=parameters_set.iloc[:, 1])\n",
    "\n",
    "    behavioral_df = simulate_ANNRDM_individual(n_trials=n_trials, trials_info_df=word_nword_df,\n",
    "                                         parameters_set=parameters_set)\n",
    "    stan_parameters = get_stan_parameters(behavioral_df)\n",
    "    fit = rdm_model.sample(data=stan_parameters,\n",
    "                       iter_sampling=n_sample, \n",
    "                       iter_warmup=n_warmup,\n",
    "                       chains=n_chains,\n",
    "                       show_console=False)\n",
    "    \n",
    "    df = fit.summary()\n",
    "    badRhat = False\n",
    "    for f in df[\"R_hat\"]:\n",
    "        if f >= 1.01 or f <= 0.9:\n",
    "            badRhat = True\n",
    "    \n",
    "    if badRhat:\n",
    "        print(\"Split R-hat values are not satisfactory for all parameters. repeating iteration\") \n",
    "    else:\n",
    "        save_results_to_csv(fit, parameters_set)\n",
    "        iteration_count += 1\n",
    "        print(f\"Iteration for participant {iteration_count+1} Finished\") \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632d370f-7ebe-4acc-84bd-db5123551216",
   "metadata": {},
   "source": [
    "## Particpants parameter recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f6a76e-0d92-4a1a-a6bb-db355a548c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recovery_data = pd.read_csv(\"ANNRDM_FULL_recovery_results.csv\", header=0)\n",
    "parameters = [\"k_1\", \"k_2\", \"alpha\", \"b\", \"threshold_word\",  \"threshold_nonword\", \"m\", \"g\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864467e-7d2e-4249-97de-e40f7aeaa049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 2, figsize=(15,15))\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.8)\n",
    "raveled_axes = axes.ravel()\n",
    "\n",
    "for index, parameter in enumerate(parameters):      \n",
    "    posterior_mean = recovery_data[\"mean_\"+parameter]\n",
    "    posterior_median = recovery_data[\"median_\"+parameter]\n",
    "    true = recovery_data[\"real_\"+parameter]\n",
    "    raveled_axes[index].scatter(true, posterior_mean, color=\"tomato\",\n",
    "                                zorder=10)\n",
    "    raveled_axes[index].scatter(true, posterior_median, color=\"yellow\",\n",
    "                                zorder=9)\n",
    "    raveled_axes[index].vlines(x=true.to_numpy(), linewidth=2,\n",
    "                               ymin=recovery_data[\"HDI_\"+parameter+\"_bottom\"].to_numpy(),\n",
    "                               ymax=recovery_data[\"HDI_\"+parameter+\"_top\"].to_numpy())\n",
    "    raveled_axes[index].set_title(parameter)\n",
    "    min_true_point =true.min()\n",
    "    max_true_point = true.max()\n",
    "    recoverline = raveled_axes[index].axline(\n",
    "        (min_true_point, min_true_point),\n",
    "        (max_true_point, max_true_point))\n",
    "    plt.setp(recoverline, linewidth=3, color=\"grey\")\n",
    "    r2 = r2_score(true, posterior_mean)\n",
    "    raveled_axes[index].text(0.1, 0.9, f\"R2: {r2:.2f}\", horizontalalignment='center',\n",
    "     verticalalignment='center', transform=raveled_axes[index].transAxes)\n",
    "    \n",
    "plt.savefig(root + \"Parameter Recovery/Plots/ANN-RDM_Full_FC_ParameterRecovery.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50183958-064d-4b12-ab7e-46f8b3846aef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67387f2-7c8a-4446-ad36-905c40420c23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stan",
   "language": "python",
   "name": "stan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
